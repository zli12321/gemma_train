model: Qwen/Qwen3-4B
trust_remote_code: true
model_class: llm

template: qwen3_nothink

# PEFT Configuration
peft_config:
  name: lora
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules: all

# Kernel Config
kernel_config:
  name: auto
  include_kernels: auto

# FSDP Config
dist_config:
  name: fsdp2
  dcp_path: null

### data
train_dataset: data/v1_sft_demo.yaml

### training
output_dir: ./outputs/test_lora
micro_batch_size: 1
global_batch_size: 4
cutoff_len: 2048
learning_rate: 1.0e-4
bf16: true
max_steps: 10

### sample
sample_backend: hf
max_new_tokens: 128
